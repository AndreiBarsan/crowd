{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Similarity Graph Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    " * Improve graph interactivity.\n",
    " * Display both ground truth and votes in graph.\n",
    " * Explore using simhashing to speed up the similarity lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph, Graph\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import datetime\n",
    "import io\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.seed(0xC0FFEE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ../data.py\n",
    "%run ../config.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the topic information for improved manual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOPIC_DESCRIPTION_FILE = os.path.join(DATA_ROOT, 'topics.mq09.cs2011-test-topics.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree\n",
    "\n",
    "class Topic(object):\n",
    "    required = ['number', 'query']\n",
    "    \n",
    "    def __init__(self, entries):\n",
    "        for field in self.required:\n",
    "            assert field in entries.keys()\n",
    "            \n",
    "        self.__dict__.update(entries)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"%s:%s\" % (self.number, self.query)\n",
    "\n",
    "xml_root = xml.etree.ElementTree.parse(TOPIC_DESCRIPTION_FILE).getroot()\n",
    "topic_info = [Topic({field.attrib['name'] : field.text for field in row}) for row in xml_root]\n",
    "id_topic_info = {topic.number : topic for topic in topic_info}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the relevance judgements to improve the visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "judgements = read_useful_judgement_labels(JUDGEMENT_FILE)\n",
    "\n",
    "# Note: it seems to be normal that there are duplicates in this dataset.\n",
    "test_data = read_expert_labels(TEST_LABEL_FILE_SHARED, header=True, sep=',') + \\\n",
    "    read_expert_labels(TEST_LABEL_FILE_TEAMS, header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic we are exploring: [20704:detroit riot]\n"
     ]
    }
   ],
   "source": [
    "topics = { l.topic_id for l in judgements }\n",
    "\n",
    "# Some topic ID we want to visualize.\n",
    "target_topic_id = '20704'\n",
    "assert target_topic_id in topics\n",
    "print(\"Topic we are exploring: [%s]\" % id_topic_info[target_topic_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465 turk judgements in topic of 90 documents.\n",
      "AVG: 5.17 judgements per documents\n"
     ]
    }
   ],
   "source": [
    "topic_judgements = [j for j in judgements if j.topic_id == target_topic_id]\n",
    "doc_ids_in_topic = {j.doc_id for j in topic_judgements}\n",
    "print(\"%d turk judgements in topic of %d documents.\" % (len(topic_judgements), len(doc_ids_in_topic)))\n",
    "print(\"AVG: %.2f judgements per documents\" % (len(topic_judgements) / len(doc_ids_in_topic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the document data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FULLTEXT_FOLDER = os.path.join(DATA_ROOT, 'url-header-html-txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_folder = os.path.join(FULLTEXT_FOLDER, str(target_topic_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 141 files.\n"
     ]
    }
   ],
   "source": [
    "# Grab every file from the topic, and only look at those whose\n",
    "# names end in '.txt', i.e. the HTML text with all HTML tags stripped\n",
    "# away.\n",
    "file_names = [f for f in os.listdir(topic_folder) \n",
    "                 if os.path.isfile(os.path.join(topic_folder, f))\n",
    "                 and f.endswith(\".txt\")]\n",
    "print(\"We have %d files.\" % len(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_file(name):\n",
    "    with io.open(name, 'r') as file:\n",
    "        return file.read()\n",
    "    \n",
    "    \n",
    "# A map of file names (IDs) to their contents.\n",
    "doc_id_to_doc = {}\n",
    "corpus = []\n",
    "\n",
    "for f in file_names:\n",
    "    doc_id = f[:f.rfind('.')]\n",
    "    text = read_file(os.path.join(topic_folder, f))\n",
    "    doc_id_to_doc[doc_id] = text\n",
    "    corpus.append((doc_id, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DocumentEdge(object):\n",
    "    \"\"\" Represents an edge in the document similarity graph.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, from_document_id, to_document_id, similarity):\n",
    "        self.from_document_id = from_document_id\n",
    "        self.to_document_id = to_document_id\n",
    "        self.similarity = similarity\n",
    "\n",
    "\n",
    "class DocumentNode(object):\n",
    "    \"\"\" Represents a node (a document) in the document similarity graph.\n",
    "    \n",
    "    Attributes:\n",
    "        topic_id: The int ID of the topic to which the document belongs.\n",
    "        document_id: The ID of the document, without any file extension.\n",
    "        document_name: The full name of the document (usually its ID, plus\n",
    "            its extension).\n",
    "        neighbors: A list of 'DocumentEdge' objects, representing this\n",
    "            node's neighbors.\n",
    "    \"\"\"\n",
    "    def __init__(self, topic_id, document_id, document_name, neighbors):\n",
    "        self.topic_id = topic_id\n",
    "        self.document_id = document_id\n",
    "        self.document_name = document_name\n",
    "        self.neighbors = neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DocumentGraph(object):\n",
    "    \"\"\" Represents a graph with documents as nodes, and similarities as\n",
    "    edges.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, topic, nodes):\n",
    "        self.nodes = nodes\n",
    "        self.topic = topic\n",
    "        self.topic_id = topic.number\n",
    "        self.nodes_by_id = {node.document_id: node for node in nodes}\n",
    "        \n",
    "    def get_node(self, document_id):\n",
    "        return self.nodes_by_id[document_id] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and render the document graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def build_document_graph(topic_id, file_names, corpus, sim_threshold=0.80):\n",
    "    file_names_np = np.array(file_names)\n",
    "    vectorizer = TfidfVectorizer(min_df=1)\n",
    "    # Make sure we just pass document texts, and not (doc_id, text) tuples to\n",
    "    # the tf-idf vectorizer.\n",
    "    term_doc_matrix = vectorizer.fit_transform([text for doc_id, text in corpus])\n",
    "    # TODO(andrei) This kernel is a popular choice for computing the\n",
    "    # similarity of documents represented as tf-idf vectors.\n",
    "    # cosine_similarity accepts scipy.sparse matrices. (Note that the tf-idf\n",
    "    # functionality in sklearn.feature_extraction.text can produce normalized\n",
    "    # vectors, in which case cosine_similarity is equivalent to linear_kernel,\n",
    "    # only slower.)\n",
    "\n",
    "    # Automagically computes ALL pairwise cosine similarities between\n",
    "    # the documents in our corpus.\n",
    "    similarities = cosine_similarity(term_doc_matrix)\n",
    "\n",
    "    graph_nodes = []\n",
    "    total_edges = 0\n",
    "\n",
    "    # Whether we should print out larger clusters to facilitate manual inspection.\n",
    "    print_large_clusters = False\n",
    "\n",
    "    for row_index in range(len(similarities)):\n",
    "        sims = similarities[row_index]\n",
    "        doc_id, document = corpus[row_index]\n",
    "\n",
    "        mask = sims > sim_threshold\n",
    "        # Make sure we don't have an edge to ourselves, since we're always\n",
    "        # 100% similar to ourselves.\n",
    "        mask[row_index] = False\n",
    "        relevant_sims = sims[mask]\n",
    "        relevant_docs = file_names_np[mask]\n",
    "\n",
    "        neighbors = []\n",
    "        for sim, other_doc_name in zip(relevant_sims, relevant_docs):\n",
    "            other_doc_id = other_doc_name[:other_doc_name.rfind('.')]\n",
    "            neighbors.append(DocumentEdge(doc_id, other_doc_id, sim))\n",
    "\n",
    "        node = DocumentNode(topic_id, doc_id, file_names_np[row_index], neighbors)\n",
    "        total_edges += len(neighbors)\n",
    "        graph_nodes.append(node)\n",
    "\n",
    "        # Sanity check: every document must be 100% similar to itself.\n",
    "        assert np.allclose(sims[row_index], 1.0)\n",
    "\n",
    "        # Explicitly print out larger clusters to facilitate manual inspection.\n",
    "        if print_large_clusters and len(relevant_sims) > 15:\n",
    "            print(\"Document %s has some similar friends!\" % doc_id)\n",
    "            print(list(zip(relevant_sims, relevant_docs)))\n",
    "\n",
    "    # Note: this treats similarity edges as directed, even though they aren't.\n",
    "    # Moreover, even though they should be, the edges aren't always 100% \"undirected\",\n",
    "    # since (perhaps due to rounding errors) some similarity edges end up being only\n",
    "    # one-way.\n",
    "    print(\"Built graph with %d total edges.\" % (total_edges / 2))\n",
    "    \n",
    "    topic = id_topic_info[topic_id]\n",
    "    return DocumentGraph(topic, graph_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_relevant(topic_id, ground_truth_data):\n",
    "    \"\"\" Returns a set of relevant and a set of non-relevant document IDs\n",
    "    from the specified topic.\n",
    "    \n",
    "    \"\"\"\n",
    "    topic_test = [j for j in ground_truth_data if j.topic_id == topic_id]\n",
    "    judgements_by_doc_id = {j.document_id : j for j in topic_test}\n",
    "    \n",
    "    # TODO(andrei) Fix issue with 'is_relevant()' function for labels == -1.\n",
    "    relevant_documents = {j.document_id for j in topic_test if j.label > 0}\n",
    "    non_relevant_documents = {j.document_id for j in topic_test if j.label == 0}\n",
    "\n",
    "    return relevant_documents, non_relevant_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_graph(graph, topic_folder, ground_truth_data):\n",
    "    \"\"\" Renders the specified document graph using graphviz.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    dot = Graph(comment='Similarity graph', engine='neato')\n",
    "    dot.body.append('size=\"18,18\"')\n",
    "    dot.body.append('splines=true;')\n",
    "    dot.body.append('overlap=scalexy;')\n",
    "    dot.body.append('nodesep=25.0;')\n",
    "    dot.body.append('label=\"Topic: %s (%s)\"' % (graph.topic.description, graph.topic.query))\n",
    "    \n",
    "    relevant_documents, non_relevant_documents = get_relevant(graph.topic_id, ground_truth_data)\n",
    "\n",
    "    SHORT_NAME_OFFSET = 7\n",
    "    FILE_URI_PREFIX = 'file://'\n",
    "\n",
    "    for node in graph.nodes:\n",
    "        name = node.document_id\n",
    "        short_name = name[name.rfind('-') - SHORT_NAME_OFFSET : name.rfind('.'):]\n",
    "        full_path = FILE_URI_PREFIX + os.path.join(topic_folder, name + \".txt\")\n",
    "        color = \"white\"\n",
    "        if name in relevant_documents:\n",
    "            color = \"green\"\n",
    "        if name in non_relevant_documents:\n",
    "            color = \"red\"\n",
    "        dot.node(name, label=short_name, fillcolor=color, fontsize='7', shape='box', height='0', width='0',\n",
    "                 tooltip=name, URL=full_path, style='filled')\n",
    "\n",
    "\n",
    "    for node in graph.nodes:\n",
    "        for neighbor in node.neighbors:\n",
    "            if neighbor.to_document_id > neighbor.from_document_id:\n",
    "                label = \"%.3f\" % neighbor.similarity\n",
    "                dot.edge(\n",
    "                    neighbor.from_document_id, neighbor.to_document_id,\n",
    "                    label=label,\n",
    "                    fontsize='6')\n",
    "                \n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built graph with 193 total edges.\n",
      "Topic description: [What happened during the Detroit riots?]\n"
     ]
    }
   ],
   "source": [
    "graph = build_document_graph(target_topic_id, file_names, corpus)\n",
    "print(\"Topic description: [%s]\" % graph.topic.description)\n",
    "graph_dot = visualize_graph(graph, topic_folder, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
